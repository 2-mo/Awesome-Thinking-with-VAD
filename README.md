# Awesome LLM4VAD

A curated list of papers and resources on Large Language Models for Video Anomaly Detection (VAD).


## Contents

- [Overview](#overview)
- [Papers (2025)](#papers-2025)
- [Papers (2024)](#papers-2024)
- [Contributing](#contributing)
- [License and Credits](#license-and-credits)

---

## Overview

This list collects representative works that leverage LLMs or vision-language models for video anomaly detection, explanation, and understanding. Entries are grouped by year with links to paper and code, plus a preview figure when available.

ä¸Šä¸‹æ–‡ä¾èµ–ï¼ˆå¤æ‚æ€§ï¼‰ï¼šå¼‚å¸¸å¾€å¾€æ˜¯é•¿æ—¶åºäº‹ä»¶ï¼ˆæ‰“æ–—ã€äº‹æ•…ï¼‰ï¼Œéœ€è¦ç»“åˆå‰åå› æœä¸åœºæ™¯å…³ç³»æ‰èƒ½æ­£ç¡®åˆ¤å®šã€‚

æ­§ä¹‰æ··æ·†ï¼ˆæ¨¡ç³Šæ€§ï¼‰ï¼šå±€éƒ¨è¡Œä¸ºæˆ–åœºæ™¯å®¹æ˜“ä¸å¼‚å¸¸æ··æ·†ï¼ˆå¥”è·‘ vs é€ƒè·‘ã€èšé›† vs æš´ä¹±ï¼‰ï¼Œå¿…é¡»é€šè¿‡æ›´é•¿æ—¶åºå’Œå¤šæ¨¡æ€çº¿ç´¢æ¥æ¶ˆè§£ã€‚

é•¿å°¾åˆ†å¸ƒï¼ˆç¨€ç–æ€§ï¼‰ï¼šå¼‚å¸¸åœ¨è§†é¢‘æµä¸­å‡ºç°é¢‘ç‡æä½ã€æ—¶æœºä¸å¯æ§ï¼Œå•æ¬¡è§‚æµ‹æ˜“æ¼æ£€ï¼Œå¿…é¡»è·¨æ—¶ç´¯ç§¯è¯æ®ä¸å‡è®¾æ£€éªŒã€‚



#### å…¶å®â€œæ€è€ƒâ€å¹¶ä¸æ˜¯åªåœ¨å¼‚å¸¸åœºæ™¯é‡Œæ‰éœ€è¦ï¼Œè€Œæ˜¯åœ¨å¼‚å¸¸é—®é¢˜ä¸Šï¼Œå®ƒçš„å¿…è¦æ€§è¢«æ”¾å¤§ï¼š

å¸¸æ€æ¨¡å¼å®¹æ˜“é æ„ŸçŸ¥è§£å†³ï¼šæ­£å¸¸è¡Œä¸º/åœºæ™¯å æ®ç»å¤§å¤šæ•°ï¼Œè§„å¾‹æ€§å¼ºã€æ•°æ®é‡å¤§ï¼Œå•é æ„ŸçŸ¥æ¨¡å¼åŒ¹é…å°±èƒ½è¾¾åˆ°ä¸é”™çš„æ•ˆæœã€‚

å¼‚å¸¸æœ¬è´¨ä¸Šæ˜¯â€œä¸ç¡®å®šâ€ï¼šå¼‚å¸¸å¾€å¾€ç¨€ç–ã€å°‘æ ·æœ¬ï¼Œç¼ºä¹å…ˆéªŒç»Ÿè®¡æ”¯æ’‘ã€‚ä»…é å¿«é€Ÿæ„ŸçŸ¥ä¼šå‡ºç°åå·®ï¼Œéœ€è¦è·¨æ—¶æ•´åˆå’Œå‡è®¾æ£€éªŒæ¥å¼¥è¡¥ã€‚

å¼‚å¸¸æ¶‰åŠæ›´å¤§é£é™©ï¼šä¸€æ—¦è¯¯åˆ¤ï¼Œå¯èƒ½å¸¦æ¥ä¸¥é‡åæœï¼ˆæ¼æŠ¥å®‰å…¨äº‹ä»¶ã€è¯¯æŠ¥å¹²æ‰°ç³»ç»Ÿï¼‰ï¼Œå› æ­¤å¿…é¡»å¼•å…¥æ›´æ…¢ã€æ›´ç¨³å¥çš„å†³ç­–æœºåˆ¶ã€‚

å¼‚å¸¸å¾€å¾€æ‰“ç ´å¸¸è§„ï¼šå®ƒä»¬å¯èƒ½è¡¨ç°ä¸ºå¤æ‚çš„ä¸Šä¸‹æ–‡ä¾èµ–ã€æ¨¡ç³Šçš„è¯­ä¹‰æ··æ·†ã€é•¿å°¾çš„ç¨€ç–åˆ†å¸ƒâ€”â€”è¿™äº›éƒ½æ°å¥½æ˜¯â€œæ€è€ƒâ€æ“…é•¿å¤„ç†çš„ã€‚


æˆ‘ä»¬éœ€è¦çš„æ˜¯æ¨ç†ï¼Œè€Œä¸ä»…æ˜¯äº‹åè§£é‡Šã€‚


### Curiosity-driven Learning

Humans monitor learning progress in curiosity-driven exploration (Nature Communications 2021) [[paper](https://www.nature.com/articles/s41467-021-26196-w)]
å‘ç°äººç±»åœ¨æ¢ç´¢ä¸­ä¼šâ€œç›¯ç€å­¦ä¹ è¿›åº¦â€æœ¬èº«ï¼šæ›´åå¥½èƒ½å¸¦æ¥æ›´å¤§çŸ¥è¯†å¢ç›Š/è¯¯å·®ä¸‹é™ç‡çš„é€‰æ‹©ã€‚è¡Œä¸ºä¸æ¨¡å‹æ”¯æŒâ€œä»¥å­¦ä¹ è¿›æ­¥ä¸ºå›æŠ¥â€çš„å¥½å¥‡å¿ƒæœºåˆ¶

Curiosity-driven Exploration by Self-supervised Prediction (ICML 2017 (PMLR v70)) [[paper](https://proceedings.mlr.press/v70/pathak17a/pathak17a.pdf)]

Computational mechanisms of curiosity and goal-directed exploration (Neuroscience 2019) [[paper](https://elifesciences.org/articles/41703)]



---

## ğŸ“Š Benchmarks and Datasets




æ•°æ®é›†ï¼šDriving Anomaly Detection Honda Research Institute
<https://usa.honda-ri.com/hdd#Videos>

NWPU-Campus
Ubnormal
TAD
X-Man
XD-Violence

shanghaitech-anomaly-detection [[project](https://svip-lab.github.io/dataset/campus_dataset.html)] â€” Campus surveillance anomaly set; classic weakly supervised benchmark.

[UCF-Crime](https://www.crcv.ucf.edu/research/real-world-anomaly-detection-in-surveillance-videos/) â€” Real-world surveillance anomaly dataset with long untrimmed videos.

Multi-Scenario Anomaly Detection (MSAD) Dataset (NeurIPS 2024) [![Project](https://img.shields.io/badge/Project-blue?logo=safari)](https://msad-dataset.github.io/) [![arXiv](https://img.shields.io/badge/arXiv-2402.04857-b31b1b?logo=arxiv)](https://arxiv.org/pdf/2402.04857) â€” Large-scale, multi-scene anomaly benchmark.


https://video-holmes.github.io/Page.github.io/



<https://github.com/okankop/Driver-Anomaly-Detection>

https://www.cs.cmu.edu/~roadwork/ (ICCV 2025)



### Metrics & Evaluation

- Coming soon: common tasks, metrics, and evaluation protocols.

---



## Papers (2025)


ICCV 2025

FE-CLIP: Frequency Enhanced CLIP Model for Zero-Shot Anomaly Detection and Segmentation

Wave-MambaAD: Wavelet-driven State Space Model for Multi-class Unsupervised Anomaly Detection

MultiADS: Defect-aware Supervision for Multi-type Anomaly Detection and Segmentation in Zero-Shot Learning

ReMP-AD: Retrieval-enhanced Multi-modal Prompt Fusion for Few-Shot Industrial Visual Anomaly Detection

Aligning Effective Tokens with Video Anomaly in Large Language Models

Toward Long-Tailed Online Anomaly Detection through Class-Agnostic Concepts

Towards Real Unsupervised Anomaly Detection Via Confident Meta-Learning

Anomaly Detection of Integrated Circuits Package Substrates Using the Large Vision Model SAIC: Dataset Construction, Methodology, and Application

Beyond Walking: A Large-Scale Image-Text Benchmark for Text-based Person Anomaly Search

Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection

Triad: Empowering LMM-based Anomaly Detection with Expert-guided Region-of-Interest Tokenizer and Manufacturing Process

Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images

HumanSAM: Classifying Human-centric Forgery Videos in Human Spatial, Appearance, and Motion Anomaly


SALAD -- Semantics-Aware Logical Anomaly Detection

Fine-grained Abnormality Prompt Learning for Zero-shot Anomaly Detection

FIND: Few-Shot Anomaly Inspection with Normal-Only Multi-Modal Data


Autoregressive Denoising Score Matching is a Good Video Anomaly Detector


DictAS: A Framework for Class-Generalizable Few-Shot Anomaly Segmentation via Dictionary Lookup

DecAD: Decoupling Anomalies in Latent Space for Multi-Class Unsupervised Anomaly Detection


Sequential keypoint density estimator: an overlooked baseline of skeleton-based video anomaly detection


RareCLIP: Rarity-aware Online Zero-shot Industrial Anomaly Detection


Debiasing Trace Guidance: Top-down Trace Distillation and Bottom-up Velocity Alignment for Unsupervised Anomaly Detection





åˆ†å¸ƒå¤–æ£€æµ‹ï¼š
Beyond Pixel Uncertainty: Bounding the OoD Objects in Road Scenes

Equipping Vision Foundation Model with Mixture of Experts for Out-of-Distribution Detection

Adaptive Prompt Learning via Gaussian Outlier Synthesis for Out-of-distribution Detection

FA: Forced Prompt Learning of Vision-Language Models for Out-of-Distribution Detection





### VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models (CVPR 2025)

[![CVPR](https://img.shields.io/badge/CVPR-2025-1E90FF)](https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_VERA_Explainable_Video_Anomaly_Detection_via_Verbalized_Learning_of_Vision-Language_CVPR_2025_paper.pdf)
[![Code](https://img.shields.io/github/stars/vera-framework/VERA?style=social&label=Code&logo=github)](https://github.com/vera-framework/VERA)

Highlight: Verbalized learning makes VLM-based VAD explainable with natural-language rationales and clearer decision traces.

![VERA preview](./assets/2025-cvpr-vera.png)

---

### Holmes-VAU: Towards Long-term Video Anomaly Understanding at Any Granularity (CVPR 2025)

[![CVPR](https://img.shields.io/badge/CVPR-2025-1E90FF)](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Holmes-VAU_Towards_Long-term_Video_Anomaly_Understanding_at_Any_Granularity_CVPR_2025_paper.pdf)
[![Code](https://img.shields.io/github/stars/pipixin321/HolmesVAU?style=social&label=Code&logo=github)](https://github.com/pipixin321/HolmesVAU)

Highlight: Targets long-horizon anomaly understanding with fine-to-coarse granularity, improving temporal coverage and robustness.

![Holmes-VAU preview](./assets/2025-cvpr-holmes-vau.png)

---

## Papers (2024)

### VadCLIP: Adapting Vision-Language Models for Weakly Supervised Video Anomaly Detection (AAAI 2024)

[![AAAI](https://img.shields.io/badge/AAAI-2024-1F77B4)](https://arxiv.org/abs/2308.11681)
[![arXiv](https://img.shields.io/badge/arXiv-2308.11681-b31b1b?logo=arxiv)](https://arxiv.org/abs/2308.11681)
[![Code](https://img.shields.io/github/stars/nwpu-zxr/VadCLIP?style=social&label=Code&logo=github)](https://github.com/nwpu-zxr/VadCLIP)

Highlight: Adapts CLIP-style visionâ€“language alignment to weakly supervised VAD, reducing annotation demands.

![VadCLIP preview](./assets/2024-aaai-vadclip.png)

---

### EventVAD: Training-Free Event-Aware Video Anomaly Detection ï¼ˆACM MM 2025ï¼‰

https://arxiv.org/abs/2504.13092

![alt text](./assets/eventvad-acmmm25.png)


### Harnessing Large Language Models for Training-free Video Anomaly Detection (CVPR 2024)

[![CVPR](https://img.shields.io/badge/CVPR-2024-1E90FF)](https://openaccess.thecvf.com/content/CVPR2024/papers/Zanella_Harnessing_Large_Language_Models_for_Training-free_Video_Anomaly_Detection_CVPR_2024_paper.pdf)
[![Code](https://img.shields.io/github/stars/lucazanella/lavad?style=social&label=Code&logo=github)](https://github.com/lucazanella/lavad)

Highlight: Leverages LLM priors for training-free anomaly detection via promptable semantic knowledge.

![Training-free VAD preview](./assets/2024-cvpr-training-free-vad.png)

---

### Follow the Rules: Reasoning for Video Anomaly Detection with Large Language Models (ECCV 2024)

[![ECCV](https://img.shields.io/badge/ECCV-2024-0B84FE)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/10568.pdf)
[![Code](https://img.shields.io/github/stars/Yuchen413/AnomalyRuler?style=social&label=Code&logo=github)](https://github.com/Yuchen413/AnomalyRuler)

Highlight: Injects rule-based reasoning with LLMs to guide anomaly decisions and improve interpretability.

![AnomalyRuler preview](./assets/2024-eccv-anomalyruler.png)

---

### Video Anomaly Detection and Explanation via Large Language Models (arXiv 2024)

[![arXiv](https://img.shields.io/badge/arXiv-2401.05702v1-b31b1b?logo=arxiv)](https://arxiv.org/pdf/2401.05702v1)

Highlight: Couples VAD with LLM-generated explanations to provide interpretable, text-based rationales.

![LLM VAD + Explanation preview](./assets/2024-arxiv-vad-llm-explanation.png)

---

### HAWK: Learning to Understand Open-World Video Anomalies (NeurIPS 2024)

[![NeurIPS](https://img.shields.io/badge/NeurIPS-2024-2DB55D)](https://arxiv.org/pdf/2405.16886)
[![arXiv](https://img.shields.io/badge/arXiv-2405.16886-b31b1b?logo=arxiv)](https://arxiv.org/pdf/2405.16886)
[![Code](https://img.shields.io/github/stars/jqtangust/hawk?style=social&label=Code&logo=github)](https://github.com/jqtangust/hawk)

Highlight: Pursues open-world anomaly understanding with scalable concept coverage and out-of-distribution robustness.

![HAWK preview](./assets/2024-neurips-hawk.png)

---

## Related Awesome Lists

[![Awesome-Anomaly-Detection-Foundation-Models](https://img.shields.io/badge/Awesome-Anomaly_Detection_Foundation_Models-black?logo=github)](https://github.com/mala-lab/Awesome-Anomaly-Detection-Foundation-Models/tree/main?tab=readme-ov-file)



å‚è€ƒæ–‡ç« 

[![HyperVD](https://img.shields.io/badge/To--Sort-HyperVD-lightgrey?logo=github)](https://github.com/xiaogangpeng/HyperVD)


ROADWork: A Dataset and Benchmark for Learning to Recognize, Observe, Analyze and Drive Through Work Zones
- **ä½œè€…**ï¼šAnurag Ghosh, Shen Zheng, Robert Tamburo, ç­‰
- **ä¸»è¦å†…å®¹**ï¼šæå‡ºROADWorkæ•°æ®é›†ï¼Œä¸“æ³¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸‹çš„æ–½å·¥åŒºåŸŸè¯†åˆ«ä¸å¯¼èˆªï¼Œæå‡æ¨¡å‹åœ¨é•¿å°¾åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚
- **é“¾æ¥**ï¼š[https://www.cs.cmu.edu/~roadwork/](https://www.cs.cmu.edu/~roadwork/)


Passing the Driving Knowledge Test
- **ä½œè€…**ï¼šMaolin Wei, Wanzhou Liu, Eshed Ohn-Bar
- **ä¸»è¦å†…å®¹**ï¼šæå‡ºDriveQAæ•°æ®é›†ï¼Œè¯„æµ‹LLM/MLLMåœ¨äº¤é€šè§„åˆ™ç†è§£ä¸æ¨ç†èƒ½åŠ›ã€‚
- **é“¾æ¥**ï¼š[https://driveqaiccv.github.io](https://driveqaiccv.github.io)


https://github.com/Tangkfan/Awesome-Temporal-Video-Grounding



ï¼»ICML2025å›¾åˆå¹¶é•¿è§†é¢‘å­—å¹•ï¼½ Fine-Grained Captioning of Long Videos through Scene Graph Consolidation Objective â€¢ Problemï¼š ç°æœ‰ VIM å› æœ‰é™çš„æ—¶é—´æ„Ÿå—é‡ ï¼ˆlimited temporal receptive fieldsï¼‰ï¼Œéš¾ä»¥å¤„ç†é•¿è§†é¢‘å­—å¹•ç”Ÿæˆä»»åŠ¡ â€¢ Existing Solutions & Drawbacks: â€¢ Memory/Recursive Frameworksï¼š éœ€è¦åœ¨ç›®æ ‡æ•°æ®é›†ä¸Šè¿›è¡Œç›‘ç£å¼ fine-tuningï¼Œæ³›åŒ–èƒ½åŠ›å—é™ ã€‚ LLM-based Consolidationï¼š ç›´æ¥åˆ©ç”¨LIMæ±‡æ€»å„è§†é¢‘ç‰‡æ®µä¿¡æ¯ï¼Œå­˜åœ¨é«˜æ˜‚çš„æ¨ç†å¼€é”€å’Œå·¨å¤§çš„è®¡ç®—èµ„æºéœ€æ±‚ â€¢ Proposed Solutionï¼š æå‡ºä¸€ç§åŸºäºå›¾åˆå¹¶çš„zero-shoté•¿è§†é¢‘å­—å¹•æ¡†æ¶ï¼Œæ— éœ€ fine-tuningï¼Œå…¼å…·é«˜æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ æ ¸å¿ƒæ€è·¯æ˜¯å°†éç»“æ„åŒ–çš„å¤šæºæ–‡æœ¬ä¿¡æ¯æ•´åˆé—®é¢˜ï¼Œè½¬åŒ–ä¸ºç»“æ„åŒ–çš„å›¾èŠ‚ç‚¹åˆå¹¶é—®é¢˜